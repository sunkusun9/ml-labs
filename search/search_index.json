{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"ml-labs","text":"<p>ML pipeline and experiment management library.</p>"},{"location":"#overview","title":"Overview","text":"<p>ml-labs provides a structured framework for building, managing, and deploying machine learning pipelines.</p> <ul> <li>Pipeline: Node graph data structure for separating ML concerns</li> <li>Experimenter: Experiment execution and management</li> <li>Trainer: Training with cross-validation splits</li> <li>Inferencer: Apply trained pipelines to new data</li> </ul>"},{"location":"#installation","title":"Installation","text":"<pre><code>pip install ml-labs\n</code></pre> <p>Optional dependencies:</p> <pre><code>pip install ml-labs[xgboost]\npip install ml-labs[lightgbm]\npip install ml-labs[all]\n</code></pre>"},{"location":"concepts/","title":"Concepts","text":"<p>Coming soon.</p>"},{"location":"concepts/architecture/","title":"Architecture","text":"<p>ml-labs is composed of four core modules, each with a distinct responsibility.</p> <pre><code>Pipeline \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 defines the node graph (structure)\n    \u2502\nExperimenter \u2500\u2500\u2500\u2500 executes builds and experiments (single dataset)\n    \u2502\nTrainer \u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500\u2500 trains with cross-validation splits\n    \u2502\nInferencer \u2500\u2500\u2500\u2500\u2500\u2500\u2500 applies trained processors to new data\n</code></pre>"},{"location":"concepts/architecture/#pipeline","title":"Pipeline","text":"<p><code>Pipeline</code> is a directed graph of nodes that describes the ML workflow structure \u2014 which processors exist, how they connect, and what parameters they use. It holds no data and performs no computation. It is the blueprint that <code>Experimenter</code> and <code>Trainer</code> read.</p>"},{"location":"concepts/architecture/#experimenter","title":"Experimenter","text":"<p><code>Experimenter</code> takes a <code>Pipeline</code> and a dataset, then executes the graph node by node. It manages:</p> <ul> <li>Build (<code>build()</code>): runs Stage nodes (transformers)</li> <li>Experiment (<code>exp()</code>): runs Head nodes (predictors)</li> <li>Collectors: pluggable objects that capture metrics, outputs, SHAP values, or stacking data during execution</li> <li>Cache: LRU cache (capacity-based) to avoid recomputing Stage outputs</li> </ul>"},{"location":"concepts/architecture/#trainer","title":"Trainer","text":"<p><code>Trainer</code> handles cross-validation. It splits data using a <code>splitter</code>, then runs each node across all splits. Stage outputs are kept in memory; Head outputs are written to disk per split. The result can be converted to an <code>Inferencer</code> via <code>to_inferencer()</code>.</p>"},{"location":"concepts/architecture/#inferencer","title":"Inferencer","text":"<p><code>Inferencer</code> holds the fitted processors produced by <code>Trainer</code>. Given new data, it runs each split's processors and aggregates the results (<code>mean</code>, <code>mode</code>, or a custom callable).</p>"},{"location":"concepts/data-flow/","title":"Data Flow","text":""},{"location":"concepts/data-flow/#overview","title":"Overview","text":"<p>Data moves through the pipeline from DataSource \u2192 Stage \u2192 Head, assembled at each node according to its <code>edges</code> definition.</p> <pre><code>DataSource\n    \u2502\n    \u25bc\nStage A  \u2500\u2500\u25ba  Stage B\n                 \u2502\n                 \u25bc\n              Head C\n</code></pre> <p>When <code>Head C</code> runs, its <code>edges</code> are resolved by pulling columns from <code>DataSource</code> and/or the outputs of <code>Stage A</code>, <code>Stage B</code>.</p>"},{"location":"concepts/data-flow/#data_dict-structure","title":"data_dict Structure","text":"<p>Each node receives a <code>data_dict</code> \u2014 a dict mapping edge keys to data.</p>"},{"location":"concepts/data-flow/#in-experimenter","title":"In Experimenter","text":"<pre><code>data_dict = {\n    'X': ((X_train, X_train_v), X_valid),\n    'y': ((y_train, y_train_v), y_valid),\n}\n</code></pre> <ul> <li><code>train</code>: full training fold data</li> <li><code>train_v</code>: training fold filtered by <code>output_var</code> (for inner validation)</li> <li><code>valid</code>: validation fold data</li> </ul>"},{"location":"concepts/data-flow/#in-trainer","title":"In Trainer","text":"<pre><code>data_dict = {\n    'X': (X_train, X_valid),\n    'y': (y_train, y_valid),\n}\n</code></pre> <p>No inner fold \u2014 data is split once by the <code>splitter</code>.</p>"},{"location":"concepts/data-flow/#cache","title":"Cache","text":"<p><code>Experimenter</code> uses an LRU cache (capacity-based, default 4 GB) to store Stage outputs. When a Stage node's output is requested by multiple downstream nodes, it is computed once and reused from cache.</p> <p><code>Trainer</code> shares the same cache instance with its parent <code>Experimenter</code>, using <code>\"train_all\"</code> as the type key to avoid collisions.</p>"},{"location":"concepts/data-flow/#x-less-nodes","title":"X-less Nodes","text":"<p>If a node's <code>edges</code> contains only <code>'y'</code> and no <code>'X'</code> (e.g. <code>LabelEncoder</code>), the <code>'y'</code> data is used as the primary input. The processor receives the y array directly, and its output becomes the new y columns.</p>"},{"location":"concepts/pipeline/","title":"Pipeline","text":"<p>A <code>Pipeline</code> is a node graph that describes the structure of an ML workflow.</p>"},{"location":"concepts/pipeline/#roles","title":"Roles","text":"<p>Every node has one of three roles:</p> Role Class Purpose DataSource (implicit) The original input data. Not a real node \u2014 represented as <code>None</code> in edges. Stage <code>TransformProcessor</code> Transforms data and passes it downstream. Stays alive to supply data to child nodes. Head <code>PredictProcessor</code> Consumes transformed data and produces predictions. Terminal node."},{"location":"concepts/pipeline/#nodes-and-groups","title":"Nodes and Groups","text":"<p>A node is the unit of execution. Each node has:</p> <ul> <li><code>processor</code>: the class that does the work (e.g. <code>StandardScaler</code>, <code>LGBMClassifier</code>)</li> <li><code>edges</code>: which upstream nodes supply which variables</li> <li><code>method</code>: method name to call on the processor</li> <li><code>adapter</code>: optional wrapper that translates data and params to framework conventions</li> <li><code>params</code>: constructor parameters for the processor</li> </ul> <p>A group (<code>PipelineGroup</code>) lets multiple nodes share configuration. Node attributes override group attributes; group attributes override parent group attributes.</p>"},{"location":"concepts/pipeline/#edges","title":"edges","text":"<p><code>edges</code> defines what data a node receives and from where.</p> <pre><code>edges = {\n    'X': [(None, ['feature1', 'feature2']),   # from DataSource\n           ('stage1', None)],                  # all columns from stage1\n    'y': [(None, 'target')],\n}\n</code></pre> <ul> <li>Keys name variable sets (<code>'X'</code>, <code>'y'</code>, <code>'sample_weight'</code>, \u2026)</li> <li>Each value is a list of <code>(node_name, var_spec)</code> pairs</li> <li><code>node_name=None</code> means DataSource</li> <li><code>var_spec</code>: <code>None</code> (all columns), <code>str</code>, <code>list</code>, or <code>callable</code></li> <li>Multiple entries for the same key are concatenated column-wise</li> <li>Child nodes inherit and extend parent group edges</li> </ul>"},{"location":"concepts/state-model/","title":"State Model","text":""},{"location":"concepts/state-model/#node-states-4-state","title":"Node States (4-State)","text":"<p>Each node in an <code>Experimenter</code> or <code>Trainer</code> tracks its own state.</p> <pre><code>init \u2500\u2500\u25ba built \u2500\u2500\u25ba finalized\n  \u25b2\n  \u2502\nerror \u2500\u2500\u25ba (reset) \u2500\u2500\u25ba init\n</code></pre> State Disk Memory Description init \u2014 \u2014 Defined in Pipeline, not yet executed built \u2713 Stage: \u2713 / Head: \u2717 Execution complete; results are accessible finalized \u2717 \u2717 Results extracted, resources released (Head only) error \u2014 error info Exception occurred; error details are preserved <p>Stage nodes cannot be finalized \u2014 they must remain available to supply data to downstream nodes.</p> <p>If an upstream Stage is in <code>error</code> state, downstream nodes naturally fail without any explicit propagation logic.</p>"},{"location":"concepts/state-model/#state-transitions","title":"State Transitions","text":"Method Transition <code>build(nodes)</code> <code>init \u2192 built</code> (Stage) <code>exp(nodes)</code> <code>init \u2192 built</code> (Head) <code>finalize()</code> <code>built \u2192 finalized</code> (Head only) <code>reset_nodes(nodes)</code> any \u2192 <code>init</code>"},{"location":"concepts/state-model/#experiment-states-2-state","title":"Experiment States (2-State)","text":"<p>At the <code>Experimenter</code> level, an experiment session is either open or closed.</p> <pre><code>open \u2500\u2500\u25ba closed\n</code></pre> State Stage objects Collector data open Kept in memory Kept closed Released Kept <p>Call <code>close_exp()</code> to transition from open to closed. This releases all Stage processor objects while preserving any data collected by Collectors.</p>"},{"location":"guide/adapters/","title":"Adapters","text":"<p>Adapters bridge the gap between ml-labs' unified interface and each ML framework's specific <code>fit()</code> parameter conventions (e.g., <code>eval_set</code>, <code>validation_data</code>, callbacks).</p>"},{"location":"guide/adapters/#adapter-interface","title":"Adapter Interface","text":"<p>All adapters extend <code>ModelAdapter</code> and may implement three members:</p>"},{"location":"guide/adapters/#get_paramsparams-logger","title":"get_params(params, logger)","text":"<p>Adjusts or filters constructor parameters before the model is instantiated. The default implementation returns <code>params</code> unchanged.</p> <p>LightGBM example \u2014 strips <code>early_stopping</code> and <code>eval_metric</code> from constructor params (they belong in <code>fit()</code>):</p> <pre><code>def get_params(self, params, logger=None):\n    return {k: v for k, v in params.items() if k not in ['early_stopping', 'eval_metric']}\n</code></pre>"},{"location":"guide/adapters/#get_fit_paramsdata_dict-params-logger","title":"get_fit_params(data_dict, params, logger)","text":"<p>Builds the keyword arguments passed to <code>model.fit()</code>. Receives a <code>data_dict</code> with <code>(train, train_v)</code> tuples per key.</p> <p>Behaviour is controlled by two constructor parameters shared by all adapters:</p> Parameter Values Effect <code>eval_mode</code> <code>'none'</code>/<code>None</code> No eval set <code>'valid'</code> Pass inner-validation fold only <code>'both'</code> Pass both train and inner-validation fold <code>verbose</code> <code>0</code> Silent <code>0 &lt; v &lt; 1</code> Progress every <code>v*100</code>% of estimators <code>v &gt;= 1</code> Every <code>v</code> iterations (framework-native)"},{"location":"guide/adapters/#result_objs","title":"result_objs","text":"<p>A class-level dict of extractable model attributes used by <code>ModelAttrCollector</code>:</p> <pre><code>result_objs = {\n    'feature_importances': (get_importance_fn, True),   # (callable, mergeable)\n    'trees':               (get_trees_fn,       False),\n}\n</code></pre> <p><code>mergeable=True</code> means the result is a <code>pd.Series</code> or <code>pd.DataFrame</code> that can be aggregated across folds by <code>get_attrs_agg()</code>.</p>"},{"location":"guide/adapters/#built-in-adapters","title":"Built-in Adapters","text":"<p>Adapters are registered by model class name and resolved automatically via <code>get_adapter()</code>. The default <code>eval_mode='both'</code>, <code>verbose=0.1</code>.</p>"},{"location":"guide/adapters/#defaultadapter","title":"DefaultAdapter","text":"<p>Used for any model not in the registry. Passes no extra fit parameters \u2014 suitable for standard sklearn transformers and estimators.</p>"},{"location":"guide/adapters/#sklearn-adapters","title":"sklearn Adapters","text":"Adapter Models result_objs <code>LMAdapter</code> <code>LinearRegression</code>, <code>LogisticRegression</code> <code>coef</code> <code>PCAAdapter</code> <code>PCA</code> <code>explained_variance</code>, <code>explained_variance_ratio</code>, <code>components</code> <code>LDAAdapter</code> <code>LinearDiscriminantAnalysis</code> <code>coef</code>, <code>intercept</code>, <code>scalings</code>, <code>explained_variance_ratio</code> <code>DecisionTreeAdapter</code> <code>DecisionTreeClassifier/Regressor</code> <code>feature_importances</code>\u2713, <code>tree</code>\u2717, <code>plot_tree</code>\u2717 <p>\u2713 mergeable, \u2717 not mergeable</p>"},{"location":"guide/adapters/#lightgbmadapter","title":"LightGBMAdapter","text":"<p>Passes <code>eval_set</code> to <code>fit()</code>. Supports <code>early_stopping</code> and <code>eval_metric</code> as node <code>params</code> (they are moved from constructor to <code>fit()</code>):</p> <pre><code>exp.set_node('lgbm', grp='lgbm_grp', params={\n    'n_estimators': 1000,\n    'early_stopping': early_stopping(50, verbose=False),\n    'eval_metric': 'auc',\n})\n</code></pre> <p><code>result_objs</code>: <code>feature_importances</code>\u2713, <code>evals_result</code>\u2713, <code>trees</code>\u2717</p>"},{"location":"guide/adapters/#xgboostadapter","title":"XGBoostAdapter","text":"<p>Passes <code>eval_set</code> to <code>fit()</code>. Progress callback is added via <code>get_params()</code>.</p> <p><code>result_objs</code>: <code>feature_importances</code>\u2713, <code>evals_result</code>\u2713, <code>trees</code>\u2717</p>"},{"location":"guide/adapters/#catboostadapter","title":"CatBoostAdapter","text":"<p>Passes <code>eval_set</code> to <code>fit()</code>. <code>verbose=0&lt;v&lt;1</code> falls back to silent (CatBoost callback API is complex).</p> <p><code>result_objs</code>: <code>feature_importances_pvc</code>\u2713, <code>feature_importances_interaction</code>\u2713, <code>evals_result</code>\u2713, <code>trees</code>\u2717</p>"},{"location":"guide/adapters/#kerasadapter","title":"KerasAdapter","text":"<p>Uses <code>validation_data=(X_val, y_val)</code> instead of <code>eval_set</code>. Both <code>'valid'</code> and <code>'both'</code> eval modes behave identically (Keras only accepts a single validation set).</p> <p><code>result_objs</code>: none</p>"},{"location":"guide/adapters/#custom-adapter","title":"Custom Adapter","text":"<pre><code>from mllabs.adapter import ModelAdapter, register_adapter\n\nclass MyAdapter(ModelAdapter):\n    def get_fit_params(self, data_dict, params=None, logger=None):\n        train_X, train_v_X = data_dict['X']\n        train_y, train_v_y = data_dict['y']\n        return {\n            'eval_set': [(train_v_X.values, train_v_y.values)],\n        }\n\nregister_adapter('MyModel', MyAdapter(eval_mode='valid', verbose=0))\n</code></pre> <p>After registration, <code>MyAdapter</code> is resolved automatically whenever a node uses <code>MyModel</code> as its processor.</p> <p>To use an adapter on a specific node or group without registering it globally:</p> <pre><code>exp.set_node('my_node', grp='my_grp', adapter=MyAdapter())\n</code></pre>"},{"location":"guide/pipeline-experimenter/","title":"Pipeline &amp; Experimenter","text":""},{"location":"guide/pipeline-experimenter/#pipeline","title":"Pipeline","text":""},{"location":"guide/pipeline-experimenter/#defining-groups-and-nodes","title":"Defining Groups and Nodes","text":"<p>A <code>Pipeline</code> is built by first defining groups, then nodes inside those groups.</p> <pre><code>from mllabs import Experimenter\nfrom sklearn.preprocessing import StandardScaler\nfrom lightgbm import LGBMClassifier\n\nexp = Experimenter(df, path='./exp', sp=StratifiedKFold(n_splits=5))\n</code></pre> <p>Groups (<code>set_grp</code>) define shared configuration for one or more nodes:</p> <pre><code>exp.set_grp('scaler', role='stage', processor=StandardScaler,\n            edges={'X': [(None, features)]}, method='fit_transform')\n\nexp.set_grp('lgbm', role='head', processor=LGBMClassifier,\n            edges={'X': [(None, features)], 'y': [(None, 'target')]},\n            method='predict_proba',\n            params={'n_estimators': 300, 'learning_rate': 0.05})\n</code></pre> <p>Nodes (<code>set_node</code>) are the executable units inside a group:</p> <pre><code>exp.set_node('lgbm_v1', grp='lgbm', params={'num_leaves': 31})\nexp.set_node('lgbm_v2', grp='lgbm', params={'num_leaves': 63})\n</code></pre> <p>Node parameters override group parameters. Processor, edges, method, and adapter are inherited if not specified on the node.</p>"},{"location":"guide/pipeline-experimenter/#name-restrictions","title":"Name Restrictions","text":"<p>Names cannot contain <code>__</code> or any of <code>/ \\ &lt; &gt; : \" | ? *</code>.</p>"},{"location":"guide/pipeline-experimenter/#edges-syntax","title":"edges Syntax","text":"<p><code>edges</code> maps variable set names to a list of <code>(node_name, var_spec)</code> pairs:</p> <pre><code>edges = {\n    'X': [\n        (None, ['col1', 'col2']),   # specific columns from DataSource\n        ('scaler_node', None),       # all output columns from a Stage node\n    ],\n    'y': [(None, 'target')],\n    'sample_weight': [(None, 'weight')],\n}\n</code></pre> <p><code>node_name=None</code> refers to DataSource. Multiple entries for the same key are concatenated column-wise.</p> <p>var_spec options:</p> Type Behavior <code>None</code> All columns <code>str</code> Single column by name <code>list</code> Multiple columns by name <code>callable</code> Applied to available columns, returns list"},{"location":"guide/pipeline-experimenter/#group-hierarchy-and-attribute-inheritance","title":"Group Hierarchy and Attribute Inheritance","text":"<p>Groups can be nested using the <code>parent</code> parameter:</p> <pre><code>exp.set_grp('models', role='head',\n            edges={'X': [('scaler', None)], 'y': [(None, 'target')]},\n            method='predict_proba')\n\nexp.set_grp('lgbm', role='head', processor=LGBMClassifier, parent='models')\nexp.set_grp('xgb',  role='head', processor=XGBClassifier,  parent='models')\n</code></pre> <p>Inheritance rules:</p> <ul> <li>processor, method, adapter: child overrides parent (if set)</li> <li>edges: child entries are prepended; parent entries appended (same key \u2192 extend)</li> <li>params: child wins on conflict; parent fills missing keys</li> </ul>"},{"location":"guide/pipeline-experimenter/#copy-and-compare_nodes","title":"copy and compare_nodes","text":"<p>Copy variants:</p> <pre><code>p2 = pipeline.copy()                          # full copy\np_stage = pipeline.copy_stage()               # stage groups/nodes only\np_sub = pipeline.copy_nodes(['node_a', 'node_b'])  # nodes + all ancestors\n</code></pre> <p>Comparing nodes with the same processor:</p> <pre><code>diffs = exp.pipeline.compare_nodes(['lgbm_v1', 'lgbm_v2', 'lgbm_v3'])\n# Returns {processor_name: DataFrame} showing only differing params and X variable sets\n</code></pre> <p>Columns with identical values across all nodes are excluded \u2014 only differences are shown.</p>"},{"location":"guide/pipeline-experimenter/#experimenter","title":"Experimenter","text":""},{"location":"guide/pipeline-experimenter/#instantiation","title":"Instantiation","text":"<pre><code>from sklearn.model_selection import StratifiedKFold, ShuffleSplit\nfrom mllabs import Experimenter\n\nexp = Experimenter(\n    data=df,\n    path='./my_exp',\n    sp=StratifiedKFold(n_splits=5),   # outer splits\n    sp_v=ShuffleSplit(n_splits=1),     # inner splits (optional)\n    splitter_params={'y': 'target'},   # columns to pass to splitter\n    title='My Experiment',\n    data_key='v1',                     # verified on load\n    cache_maxsize=4 * 1024**3,         # 4 GB LRU cache\n)\n</code></pre> <p>Use <code>Experimenter.create()</code> instead to raise an error if the path already exists.</p> <p>To reload a saved experiment:</p> <pre><code>exp = Experimenter.load('./my_exp', data=df, data_key='v1')\n</code></pre>"},{"location":"guide/pipeline-experimenter/#build-exp-workflow","title":"build / exp Workflow","text":"<pre><code>exp.build()         # builds all Stage nodes not yet built\nexp.build(rebuild=True)   # rebuilds even already-built Stage nodes\n\nexp.exp(['lgbm_v1', 'lgbm_v2'])   # runs specified Head nodes\nexp.exp()                          # runs all Head nodes\n</code></pre> <p><code>build()</code> processes Stage nodes in topological order. <code>exp()</code> first calls <code>build()</code> implicitly for any missing Stage dependencies, then runs the Head nodes.</p> <p>Both methods skip already-built nodes unless <code>rebuild=True</code> (build only).</p>"},{"location":"guide/pipeline-experimenter/#reset_nodes-show_error_nodes","title":"reset_nodes, show_error_nodes","text":"<pre><code>exp.reset_nodes(['lgbm_v1'])   # resets to init: removes node_objs, clears cache/collectors\n</code></pre> <p><code>reset_nodes</code> also propagates to downstream nodes and their Collectors and Trainers.</p> <pre><code>exp.show_error_nodes()                   # lists all nodes in error state\nexp.show_error_nodes(traceback=True)     # includes full traceback\nexp.show_error_nodes(['lgbm_v1'])        # check a specific node\n</code></pre>"},{"location":"guide/pipeline-experimenter/#finalize-reinitialize-close_exp-reopen_exp","title":"finalize / reinitialize / close_exp / reopen_exp","text":"<p><code>finalize(nodes)</code> \u2014 releases memory for built Head nodes (disk artifacts remain):</p> <pre><code>exp.finalize(['lgbm_v1'])   # built \u2192 finalized\n</code></pre> <p><code>reinitialize(nodes)</code> \u2014 removes finalized nodes from tracking (returns to init state):</p> <pre><code>exp.reinitialize(['lgbm_v1'])   # finalized \u2192 init\n</code></pre> <p><code>close_exp()</code> \u2014 finalizes all built nodes and marks the experiment as closed. Collector data is preserved.</p> <pre><code>exp.close_exp()   # open \u2192 closed\n</code></pre> <p><code>reopen_exp()</code> \u2014 clears all node objects, sets status back to open, and rebuilds Stage nodes.</p> <pre><code>exp.reopen_exp()   # closed \u2192 open (+ rebuild)\n</code></pre>"},{"location":"guide/pipeline-experimenter/#adding-and-using-collectors","title":"Adding and Using Collectors","text":"<p>Collectors capture data during <code>exp()</code> for each matched Head node.</p> <pre><code>from mllabs.collector import MetricCollector\nfrom sklearn.metrics import log_loss\nfrom mllabs import Connector\n\ncollector = MetricCollector(\n    name='metrics',\n    connector=Connector(),        # matches all nodes\n    output_var=None,              # use all output columns\n    metric_func=log_loss,\n    include_train=True,\n)\n\nexp.add_collector(collector)   # registers and runs collect() on existing built nodes\n</code></pre> <p>Querying results:</p> <pre><code>mc = exp.get_collector('metrics')\nmc.get_metric('lgbm_v1')              # per-fold metrics for one node\nmc.get_metrics(['lgbm_v1', 'lgbm_v2'])\nmc.get_metrics_agg(nodes=None, inner_fold='mean', outer_fold='mean')\n</code></pre> <p>Ad-hoc collection on already-built nodes:</p> <pre><code>exp.collect(collector, exist='skip')   # skip nodes already collected\n</code></pre> <p>Removing a collector:</p> <pre><code>exp.remove_collector('metrics')\n</code></pre>"},{"location":"guide/processors/","title":"Processors","text":"<p>ml-labs provides a set of built-in sklearn-compatible processors for common preprocessing tasks.</p>"},{"location":"guide/processors/#built-in-processors","title":"Built-in Processors","text":""},{"location":"guide/processors/#catconverter","title":"CatConverter","text":"<p>Converts specified columns to a categorical dtype (pandas <code>category</code> / polars <code>Categorical</code>).</p> <pre><code>from mllabs.processor import CatConverter\n\nCatConverter(columns=None)   # None \u2192 convert all columns\nCatConverter(columns=['city', 'gender'])\n</code></pre> <p>Output columns are the same as input columns with dtype changed. Supports pandas, polars, and numpy inputs.</p>"},{"location":"guide/processors/#catoovfilter","title":"CatOOVFilter","text":"<p>Filters out-of-vocabulary (OOV) values in categorical columns. Values not seen during <code>fit()</code> (or seen fewer than <code>min_frequency</code> times) are replaced with <code>missing_value</code>.</p> <pre><code>from mllabs.processor import CatOOVFilter\n\nCatOOVFilter(\n    columns=None,                    # None \u2192 all columns\n    min_frequency=0,                 # values with count &lt;= this are treated as OOV\n    missing_value=None,              # replacement for OOV/missing values\n    treat_empty_string_as_missing=True,\n)\n</code></pre> <p>Fitted attribute: <code>categories_</code> \u2014 dict of <code>{column: [allowed_values]}</code>.</p>"},{"location":"guide/processors/#catpaircombiner","title":"CatPairCombiner","text":"<p>Combines pairs of categorical columns into new interaction columns by concatenating their string representations.</p> <pre><code>from mllabs.processor import CatPairCombiner\n\nCatPairCombiner(\n    pairs=[('city', 'gender'), ('age_bin', 'city')],\n    sep='__',\n    treat_empty_string_as_missing=True,\n    new_col_names=None,   # None \u2192 'city__gender', 'age_bin__city'\n)\n</code></pre> <p>Output column names default to <code>colA{sep}colB</code>. Either missing value in a pair produces <code>None</code> in the output. Supports integer column indices for numpy inputs.</p>"},{"location":"guide/processors/#frequencyencoder","title":"FrequencyEncoder","text":"<p>Replaces each categorical value with its frequency (proportion or count) observed during <code>fit()</code>.</p> <pre><code>from mllabs.processor import FrequencyEncoder\n\nFrequencyEncoder(normalize=True)   # True \u2192 proportion, False \u2192 count\n</code></pre> <p>Output column names are <code>{col}_freq</code>. Unseen values at transform time receive <code>0</code>.</p>"},{"location":"guide/processors/#polars-optional-processors","title":"Polars-Optional Processors","text":"<p>Available only when <code>polars</code> is installed (<code>pip install ml-labs[polars]</code>).</p>"},{"location":"guide/processors/#polarsloader","title":"PolarsLoader","text":"<p>Reads one or more CSV files into a Polars DataFrame with automatically optimized dtypes. Uses <code>get_type_df</code> internally to analyze data ranges.</p> <pre><code>from mllabs.processor import PolarsLoader\n\nPolarsLoader(\n    predefined_types={'id': pl.Int64},   # override specific column types\n    read_method='read_csv',              # any pl.read_* method name\n)\n\n# fit: accepts a file path (str) or list of file paths\n# transform: returns pl.DataFrame with optimized schema\n</code></pre>"},{"location":"guide/processors/#exprprocessor","title":"ExprProcessor","text":"<p>Applies a dict of Polars expressions to a DataFrame via <code>with_columns</code> or <code>select</code>.</p> <pre><code>from mllabs.processor import ExprProcessor\nimport polars as pl\n\nExprProcessor(\n    dict_expr={\n        'log_income': pl.col('income').log1p(),\n        'age_sq': pl.col('age') ** 2,\n    },\n    with_columns=True,   # True \u2192 add/replace columns; False \u2192 select only these columns\n)\n</code></pre> <p>When <code>with_columns=True</code>, output includes all original columns plus the new/replaced ones. When <code>False</code>, output contains only the expressions defined in <code>dict_expr</code>.</p>"},{"location":"guide/processors/#pandasconverter","title":"PandasConverter","text":"<p>Converts a Polars DataFrame to pandas. Useful as the final stage in a Polars-based pipeline.</p> <pre><code>from mllabs.processor import PandasConverter\n\nPandasConverter(index_col=None)   # optionally set a column as the DataFrame index\n</code></pre>"},{"location":"guide/processors/#type-utilities","title":"Type Utilities","text":"<p>Utilities for analyzing column types and generating optimal dtype mappings. Useful for preprocessing pipelines that need to minimize memory usage.</p> <pre><code>from mllabs.processor import get_type_df, get_type_pl, get_type_pd, merge_type_df\n</code></pre>"},{"location":"guide/processors/#get_type_dfdf","title":"get_type_df(df)","text":"<p>Analyzes a Polars DataFrame (or LazyFrame) and returns a <code>pd.DataFrame</code> with per-column statistics and dtype-fit flags.</p> <pre><code>df_type = pl.scan_csv('train.csv').pipe(get_type_df)\n# Columns: min, max, na, count, n_unique, dtype, f32, i32, i16, i8\n# f32/i32/i16/i8: True if numeric values fit within that type's range\n</code></pre>"},{"location":"guide/processors/#get_type_pldf_type-get_type_pddf_type","title":"get_type_pl(df_type, ...) / get_type_pd(df_type, ...)","text":"<p>Convert the <code>df_type</code> analysis into a type mapping dict for Polars or pandas loading.</p> <pre><code>pl_types = get_type_pl(\n    df_type,\n    predefine={'id': pl.Int64},  # always override these\n    f32=True,                    # use Float32 where possible\n    i64=False,                   # use smallest int type that fits\n    cat_max=50,                  # columns with \u226450 unique values \u2192 Categorical\n    txt_cols=['description'],    # force these columns to String\n)\n\npd_types = get_type_pd(df_type, predefine={'id': 'int64'}, cat_max=50)\n</code></pre>"},{"location":"guide/processors/#merge_type_dfdfs","title":"merge_type_df(dfs)","text":"<p>Merges <code>df_type</code> results from multiple files (e.g., sharded datasets) into a single summary. Takes the global min/max across files to determine safe dtype ranges.</p> <pre><code>from glob import glob\n\ndf_type = merge_type_df([\n    pl.scan_csv(f).pipe(get_type_df) for f in glob('data/*.csv')\n])\n</code></pre>"},{"location":"guide/trainer-collectors/","title":"Trainer &amp; Collectors","text":""},{"location":"guide/trainer-collectors/#trainer","title":"Trainer","text":""},{"location":"guide/trainer-collectors/#cross-validation-workflow","title":"Cross-Validation Workflow","text":"<p><code>Trainer</code> runs cross-validation training independently of the main <code>Experimenter</code> experiment loop. It is created through <code>Experimenter.add_trainer()</code> and shares the same Pipeline and data cache.</p> <pre><code>trainer = exp.add_trainer(\n    name='cv',\n    data=None,              # None \u2192 use Experimenter's data\n    splitter='same',        # 'same' \u2192 use exp.sp_v (inner splitter)\n    splitter_params=None,   # None when splitter='same'\n)\n</code></pre> <p><code>splitter='same'</code> reuses the inner splitter (<code>sp_v</code>) configured on the Experimenter. Pass a scikit-learn splitter object to use a different split strategy. <code>splitter=None</code> trains on the entire dataset without splitting.</p>"},{"location":"guide/trainer-collectors/#select_head-train-process","title":"select_head, train, process","text":"<p><code>select_head(nodes)</code> specifies which Head nodes to train. All upstream Stage nodes are collected automatically.</p> <pre><code>trainer.select_head(['lgbm_v1', 'lgbm_v2'])\n</code></pre> <p><code>train()</code> trains all unbuilt nodes in topological order. Each node is trained across all splits before moving to the next node.</p> <pre><code>trainer.train()\n</code></pre> <p><code>process(data, v=None)</code> is a generator that applies the trained processors to new data, yielding one result per split.</p> <pre><code>for split_output in trainer.process(test_df):\n    # split_output: concatenated Head outputs for this split\n    ...\n</code></pre> <p><code>v</code> optionally filters output columns from the Head nodes. If multiple Heads are selected, their outputs are concatenated column-wise.</p>"},{"location":"guide/trainer-collectors/#to_inferencer","title":"to_inferencer","text":"<p>Once training is complete, convert the Trainer to an <code>Inferencer</code> for deployment:</p> <pre><code>inferencer = trainer.to_inferencer(v=None)\ninferencer.save('./inferencer')\n</code></pre> <p><code>to_inferencer()</code> copies the fitted processors out of the Trainer, so the resulting <code>Inferencer</code> is independent of the Trainer and Experimenter.</p>"},{"location":"guide/trainer-collectors/#collectors","title":"Collectors","text":"<p>Collectors capture data from Head nodes during <code>exp()</code>. Each Collector uses a <code>Connector</code> to select which nodes it observes.</p>"},{"location":"guide/trainer-collectors/#connector-based-matching","title":"Connector-Based Matching","text":"<p><code>Connector</code> controls which nodes a Collector attaches to. All three criteria are optional \u2014 only the ones provided are checked:</p> <pre><code>from mllabs import Connector\n\nConnector()                                  # matches all nodes\nConnector(node_query='lgbm')                 # regex match on node name\nConnector(node_query=['lgbm_v1', 'lgbm_v2']) # exact list match\nConnector(processor=LGBMClassifier)          # processor class match\nConnector(edges={'y': [(None, 'target')]})   # edges contain-based match\n</code></pre> <p>Multiple criteria are combined with AND logic.</p>"},{"location":"guide/trainer-collectors/#metriccollector","title":"MetricCollector","text":"<p>Computes a metric function against ground truth <code>y</code> for each fold.</p> <pre><code>from mllabs.collector import MetricCollector\nfrom sklearn.metrics import log_loss\n\nmc = MetricCollector(\n    name='metrics',\n    connector=Connector(),\n    output_var=None,          # None \u2192 all output columns\n    metric_func=log_loss,     # func(y_true, y_pred) \u2192 scalar\n    include_train=True,       # also compute on train/inner-valid folds\n)\nexp.add_collector(mc)\n</code></pre> <p>Querying results:</p> <pre><code>mc = exp.get_collector('metrics')\n\nmc.get_metric('lgbm_v1')          # Series of per-fold metrics\nmc.get_metrics(['lgbm_v1', 'lgbm_v2'])   # DataFrame\n\n# Aggregate across folds\nmean, std = mc.get_metrics_agg(\n    nodes=None,         # None \u2192 all collected nodes\n    inner_fold=True,    # aggregate inner folds (mean)\n    outer_fold=True,    # then aggregate outer folds (mean)\n    include_std=True,   # also return std DataFrame\n)\n</code></pre>"},{"location":"guide/trainer-collectors/#stackingcollector","title":"StackingCollector","text":"<p>Collects out-of-fold (OOF) predictions for stacking.</p> <pre><code>from mllabs.collector import StackingCollector\n\nsc = StackingCollector(\n    name='stacking',\n    connector=Connector(edges={'y': [(None, 'target')]}),\n    output_var=None,          # columns to collect from output\n    experimenter=exp,         # used to build index and target\n    method='mean',            # how to aggregate inner folds: 'mean', 'mode', 'simple'\n)\nexp.add_collector(sc)\n</code></pre> <p>The <code>connector.edges</code> <code>'y'</code> entry is used to extract the target column into the dataset.</p> <p>Querying results:</p> <pre><code>sc = exp.get_collector('stacking')\n\ndf = sc.get_dataset(\n    nodes=None,           # None \u2192 all collected nodes\n    include_target=True,  # append target column\n)\n# Returns a DataFrame with OOF predictions + target, indexed to match original data\n</code></pre>"},{"location":"guide/trainer-collectors/#modelattrcollector","title":"ModelAttrCollector","text":"<p>Collects model attributes such as feature importances for each fold.</p> <pre><code>from mllabs.collector import ModelAttrCollector\n\nmac = ModelAttrCollector(\n    name='importance',\n    connector=Connector(processor=LGBMClassifier),\n    result_key='feature_importances',  # key in adapter.result_objs\n    # adapter is inferred from connector.processor automatically\n)\nexp.add_collector(mac)\n</code></pre> <p>Querying results:</p> <pre><code>mac = exp.get_collector('importance')\n\nmac.get_attr('lgbm_v1')           # raw results: list of outer folds, each a list of inner folds\nmac.get_attr('lgbm_v1', idx=0)    # results for outer fold 0\n\n# Aggregate (only for mergeable result types like feature importances)\nseries = mac.get_attrs_agg(\n    node='lgbm_v1',\n    agg_inner=True,   # mean across inner folds\n    agg_outer=True,   # then mean across outer folds \u2192 returns Series\n)\n# agg_inner=True, agg_outer=False \u2192 returns DataFrame (one column per outer fold)\n# agg_inner=False \u2192 raises ValueError\n</code></pre>"},{"location":"guide/trainer-collectors/#shapcollector","title":"SHAPCollector","text":"<p>Computes SHAP values using a tree explainer for each fold.</p> <pre><code>from mllabs.collector import SHAPCollector\nfrom mllabs.filter import RandomFilter\n\nshap_c = SHAPCollector(\n    name='shap',\n    connector=Connector(processor=LGBMClassifier),\n    explainer_cls=None,       # None \u2192 shap.TreeExplainer\n    data_filter=RandomFilter(n=500, random_state=0),  # subsample for speed\n)\nexp.add_collector(shap_c)\n</code></pre> <p><code>data_filter</code> is applied to both train and valid data before computing SHAP values.</p> <p>Querying results:</p> <pre><code>shap_c = exp.get_collector('shap')\n\n# Per outer fold: list of pd.Series (one per inner fold)\nseries_list = shap_c.get_feature_importance('lgbm_v1', idx=0)\n\n# Aggregated across all folds\nimportance = shap_c.get_feature_importance_agg(\n    node='lgbm_v1',\n    agg_inner='mean',   # aggregate inner folds; None \u2192 keep MultiIndex\n    agg_outer='mean',   # aggregate outer folds; None \u2192 return DataFrame\n)\n# Both set \u2192 Series; agg_outer=None \u2192 DataFrame; agg_inner=None \u2192 MultiIndex DataFrame\n</code></pre> <p>Multiclass SHAP arrays <code>(n_samples, n_features, n_classes)</code> are automatically averaged across the class axis before computing feature importance.</p>"},{"location":"guide/trainer-collectors/#outputcollector","title":"OutputCollector","text":"<p>Saves raw <code>output_train</code> and <code>output_valid</code> arrays to disk for each fold.</p> <pre><code>from mllabs.collector import OutputCollector\n\noc = OutputCollector(\n    name='outputs',\n    connector=Connector(),\n    output_var=None,        # columns to capture\n    include_target=True,\n)\nexp.add_collector(oc)\n</code></pre> <p>Querying results:</p> <pre><code>oc = exp.get_collector('outputs')\n\nentry = oc.get_output('lgbm_v1', idx=0, inner_idx=0)\n# entry: {'output_train': (train_arr, valid_sub_arr), 'output_valid': arr, 'columns': [...]}\n\nall_entries = oc.get_outputs('lgbm_v1')\n# {(idx, inner_idx): entry, ...}\n</code></pre>"},{"location":"reference/","title":"API Reference","text":"<p>Auto-generated from source docstrings via mkdocstrings.</p>"},{"location":"reference/#modules","title":"Modules","text":"Module Contents Pipeline <code>Pipeline</code>, <code>PipelineGroup</code>, <code>PipelineNode</code> Experimenter <code>Experimenter</code>, <code>DataCache</code> Trainer <code>Trainer</code> Inferencer <code>Inferencer</code> Collectors <code>Collector</code>, <code>MetricCollector</code>, <code>StackingCollector</code>, <code>ModelAttrCollector</code>, <code>SHAPCollector</code>, <code>OutputCollector</code> Adapters <code>ModelAdapter</code>, <code>LightGBMAdapter</code>, <code>XGBoostAdapter</code>, <code>CatBoostAdapter</code>, <code>KerasAdapter</code>, sklearn adapters Connector <code>Connector</code> Filters <code>DataFilter</code>, <code>RandomFilter</code>, <code>IndexFilter</code>"},{"location":"reference/adapters/","title":"Adapters","text":""},{"location":"reference/adapters/#mllabs.adapter.ModelAdapter","title":"<code>mllabs.adapter.ModelAdapter</code>","text":"<p>               Bases: <code>ABC</code></p> <p>Abstract base class for ML framework adapters.</p> <p>Adapters translate ml-labs' unified data format into the framework-specific <code>fit()</code> parameters of each model. Registered by model class name via :func:<code>~mllabs.adapter.register_adapter</code>.</p> Class Attributes <p>result_objs (dict): <code>{key: (callable, mergeable_bool)}</code> mapping of     extractable model attributes for use with     :class:<code>~mllabs.collector.ModelAttrCollector</code>.</p>"},{"location":"reference/adapters/#mllabs.adapter.ModelAdapter.get_params","title":"<code>get_params(params, logger=None)</code>","text":"<p>\ubaa8\ub378 \uc0dd\uc131\uc790\uc5d0 \uc804\ub2ec\ud560 \ud30c\ub77c\ubbf8\ud130\ub97c \uc870\uc815</p> <p>Parameters:</p> Name Type Description Default <code>params</code> <code>dict</code> <p>\uc6d0\ubcf8 \ud30c\ub77c\ubbf8\ud130</p> required <p>Returns:</p> Name Type Description <code>dict</code> <p>\uc870\uc815\ub41c \ud30c\ub77c\ubbf8\ud130</p>"},{"location":"reference/adapters/#mllabs.adapter.ModelAdapter.get_fit_params","title":"<code>get_fit_params(data_dict, params=None, logger=None)</code>","text":"<p>\ubaa8\ub378\uc758 fit()\uc5d0 \uc804\ub2ec\ud560 \ud30c\ub77c\ubbf8\ud130\ub97c \uad6c\uc131</p> <p>Parameters:</p> Name Type Description Default <code>data_dict</code> <p>{key: (train, train_v), ...} \ud615\ud0dc\uc758 \ub370\uc774\ud130 \ub515\uc154\ub108\ub9ac</p> required <code>params</code> <code>dict</code> <p>Processor\uc5d0\uc11c \uc804\ub2ec\ub41c \ucd94\uac00 \ud30c\ub77c\ubbf8\ud130 (Optional, default=None)</p> <code>None</code> <code>logger</code> <p>Logger \uc778\uc2a4\ud134\uc2a4</p> <code>None</code> <p>Returns:</p> Name Type Description <code>dict</code> <p>fit()\uc5d0 unpacking\uc73c\ub85c \uc804\ub2ec\ud560 \ud30c\ub77c\ubbf8\ud130   \uc608: model.fit(**fit_params)</p>"},{"location":"reference/adapters/#mllabs.adapter.LightGBMAdapter","title":"<code>mllabs.adapter.LightGBMAdapter</code>","text":"<p>               Bases: <code>ModelAdapter</code></p> <p>Adapter for LightGBM models (LGBMClassifier, LGBMRegressor)</p> <p>LightGBM\ub3c4 eval_set \ud30c\ub77c\ubbf8\ud130\ub97c \uc0ac\uc6a9\ud558\uc9c0\ub9cc \uc57d\uac04 \ub2e4\ub978 \ubc29\uc2dd\uc785\ub2c8\ub2e4.</p>"},{"location":"reference/adapters/#mllabs.adapter.LightGBMAdapter.get_params","title":"<code>get_params(params, logger=None)</code>","text":"<p>\ubaa8\ub378 \uc0dd\uc131\uc790\uc5d0 \uc804\ub2ec\ud560 \ud30c\ub77c\ubbf8\ud130\ub97c \uc870\uc815</p> <p>Parameters:</p> Name Type Description Default <code>params</code> <code>dict</code> <p>\uc6d0\ubcf8 \ud30c\ub77c\ubbf8\ud130</p> required <p>Returns:</p> Name Type Description <code>dict</code> <p>\uc870\uc815\ub41c \ud30c\ub77c\ubbf8\ud130</p>"},{"location":"reference/adapters/#mllabs.adapter.LightGBMAdapter.get_fit_params","title":"<code>get_fit_params(data_dict, params=None, logger=None)</code>","text":"<p>LightGBM\uc758 fit \ud30c\ub77c\ubbf8\ud130 \uad6c\uc131</p>"},{"location":"reference/adapters/#mllabs.adapter.XGBoostAdapter","title":"<code>mllabs.adapter.XGBoostAdapter</code>","text":"<p>               Bases: <code>ModelAdapter</code></p> <p>Adapter for XGBoost models (XGBClassifier, XGBRegressor)</p> <p>XGBoost\ub294 eval_set \ud30c\ub77c\ubbf8\ud130\ub85c [(X, y), ...] \ud615\ud0dc\ub97c \ubc1b\uc2b5\ub2c8\ub2e4.</p>"},{"location":"reference/adapters/#mllabs.adapter.XGBoostAdapter.get_params","title":"<code>get_params(params, logger=None)</code>","text":"<p>XGBoost \ubaa8\ub378 \uc0dd\uc131\uc790 \ud30c\ub77c\ubbf8\ud130 \uc870\uc815 (ProgressCallback \uc124\uc815)</p>"},{"location":"reference/adapters/#mllabs.adapter.XGBoostAdapter.get_fit_params","title":"<code>get_fit_params(data_dict, params=None, logger=None)</code>","text":"<p>XGBoost\uc758 fit \ud30c\ub77c\ubbf8\ud130 \uad6c\uc131</p>"},{"location":"reference/adapters/#mllabs.adapter.CatBoostAdapter","title":"<code>mllabs.adapter.CatBoostAdapter</code>","text":"<p>               Bases: <code>ModelAdapter</code></p> <p>Adapter for CatBoost models (CatBoostClassifier, CatBoostRegressor)</p> <p>CatBoost\ub3c4 eval_set\uc744 \uc9c0\uc6d0\ud569\ub2c8\ub2e4.</p>"},{"location":"reference/adapters/#mllabs.adapter.CatBoostAdapter.get_fit_params","title":"<code>get_fit_params(data_dict, params=None, logger=None)</code>","text":"<p>CatBoost\uc758 fit \ud30c\ub77c\ubbf8\ud130 \uad6c\uc131</p>"},{"location":"reference/adapters/#mllabs.adapter.KerasAdapter","title":"<code>mllabs.adapter.KerasAdapter</code>","text":"<p>               Bases: <code>ModelAdapter</code></p> <p>Adapter for Keras models (KerasClassifier, KerasRegressor)</p> <p>Keras\ub294 validation_data \ud30c\ub77c\ubbf8\ud130\ub85c (X, y) \ud29c\ud50c\uc744 \ubc1b\uc2b5\ub2c8\ub2e4.</p>"},{"location":"reference/adapters/#mllabs.adapter.KerasAdapter.get_fit_params","title":"<code>get_fit_params(data_dict, params=None, logger=None)</code>","text":"<p>Keras\uc758 fit \ud30c\ub77c\ubbf8\ud130 \uad6c\uc131</p>"},{"location":"reference/adapters/#mllabs.adapter.LMAdapter","title":"<code>mllabs.adapter.LMAdapter</code>","text":"<p>               Bases: <code>ModelAdapter</code></p>"},{"location":"reference/adapters/#mllabs.adapter.PCAAdapter","title":"<code>mllabs.adapter.PCAAdapter</code>","text":"<p>               Bases: <code>ModelAdapter</code></p>"},{"location":"reference/adapters/#mllabs.adapter.LDAAdapter","title":"<code>mllabs.adapter.LDAAdapter</code>","text":"<p>               Bases: <code>ModelAdapter</code></p>"},{"location":"reference/adapters/#mllabs.adapter.DecisionTreeAdapter","title":"<code>mllabs.adapter.DecisionTreeAdapter</code>","text":"<p>               Bases: <code>ModelAdapter</code></p>"},{"location":"reference/adapters/#mllabs.adapter.get_adapter","title":"<code>mllabs.adapter.get_adapter(model_or_name)</code>","text":"<p>\ubaa8\ub378 \ub610\ub294 \ubaa8\ub378\uba85\uc5d0 \ud574\ub2f9\ud558\ub294 \uc5b4\ub311\ud130 \uc778\uc2a4\ud134\uc2a4\ub97c \ubc18\ud658</p> <p>Parameters:</p> Name Type Description Default <code>model_or_name</code> <p>Model instance or model class name (str)</p> required <p>Returns:</p> Name Type Description <code>ModelAdapter</code> <p>Corresponding adapter instance, or DefaultAdapter instance if not found</p> Example <p>from xgboost import XGBClassifier adapter = get_adapter(XGBClassifier)</p>"},{"location":"reference/adapters/#mllabs.adapter.get_adapter--or","title":"or","text":"<p>adapter = get_adapter('XGBClassifier')</p>"},{"location":"reference/adapters/#mllabs.adapter.register_adapter","title":"<code>mllabs.adapter.register_adapter(model_name, adapter)</code>","text":"<p>\uc0c8\ub85c\uc6b4 \uc5b4\ub311\ud130\ub97c \ub808\uc9c0\uc2a4\ud2b8\ub9ac\uc5d0 \ub4f1\ub85d</p> <p>Parameters:</p> Name Type Description Default <code>model_name</code> <code>str</code> <p>Model class name</p> required <code>adapter</code> <code>ModelAdapter</code> <p>Adapter instance</p> required Example <p>class MyCustomAdapter(ModelAdapter): ...     def get_fit_params(self, X_train, y_train, X_eval=None, y_eval=None, params=None): ...         # custom implementation ...         return {...}</p> <p>register_adapter('MyCustomModel', MyCustomAdapter())</p>"},{"location":"reference/collectors/","title":"Collectors","text":""},{"location":"reference/collectors/#mllabs.collector.Collector","title":"<code>mllabs.collector.Collector</code>","text":"<p>Base class for data collectors attached to an Experimenter.</p> <p>Subclasses override the lifecycle hooks <code>_start</code>, <code>_collect</code>, <code>_end_idx</code>, and <code>_end</code> to capture data during :meth:<code>~mllabs.Experimenter.exp</code>.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Collector name (unique within an Experimenter).</p> required <code>connector</code> <code>Connector</code> <p>Determines which Head nodes this collector attaches to.</p> required <p>Attributes:</p> Name Type Description <code>path</code> <code>Path | None</code> <p>Set by Experimenter on registration.</p>"},{"location":"reference/collectors/#mllabs.collector.Collector.has","title":"<code>has(node)</code>","text":""},{"location":"reference/collectors/#mllabs.collector.Collector.has_node","title":"<code>has_node(node)</code>","text":""},{"location":"reference/collectors/#mllabs.collector.Collector.reset_nodes","title":"<code>reset_nodes(nodes)</code>","text":""},{"location":"reference/collectors/#mllabs.collector.Collector.save","title":"<code>save()</code>","text":""},{"location":"reference/collectors/#mllabs.collector.Collector.load","title":"<code>load(path)</code>  <code>classmethod</code>","text":""},{"location":"reference/collectors/#mllabs.collector.MetricCollector","title":"<code>mllabs.collector.MetricCollector</code>","text":"<p>               Bases: <code>Collector</code></p> <p>Computes a scalar metric against ground-truth <code>y</code> for each fold.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Collector name.</p> required <code>connector</code> <code>Connector</code> <p>Node matching criteria.</p> required <code>output_var</code> <p>Column selector for prediction output. <code>None</code> uses all output columns.</p> required <code>metric_func</code> <code>callable</code> <p><code>func(y_true, y_pred) -&gt; float</code>.</p> required <code>include_train</code> <code>bool</code> <p>If <code>True</code>, also compute on train/inner-valid folds.</p> <code>False</code>"},{"location":"reference/collectors/#mllabs.collector.MetricCollector.get_metric","title":"<code>get_metric(node)</code>","text":"<p>Return per-fold metrics for a single node.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>str</code> <p>Node name.</p> required <p>Returns:</p> Type Description <p>pd.Series: Metrics indexed by <code>(split, inner_split, metric_key)</code>.</p>"},{"location":"reference/collectors/#mllabs.collector.MetricCollector.get_metrics","title":"<code>get_metrics(nodes=None)</code>","text":"<p>Return per-fold metrics for multiple nodes.</p> <p>Parameters:</p> Name Type Description Default <code>nodes</code> <p>Node query \u2014 <code>None</code> (all), <code>list</code>, or regex <code>str</code>.</p> <code>None</code> <p>Returns:</p> Type Description <p>pd.DataFrame: Rows are nodes, columns are fold MultiIndex.</p>"},{"location":"reference/collectors/#mllabs.collector.MetricCollector.get_metrics_agg","title":"<code>get_metrics_agg(nodes=None, inner_fold=True, outer_fold=True, include_std=False)</code>","text":"<p>Return aggregated metrics across folds.</p> <p>Parameters:</p> Name Type Description Default <code>nodes</code> <p>Node query. <code>None</code> uses all collected nodes.</p> <code>None</code> <code>inner_fold</code> <code>bool</code> <p>Aggregate inner folds first (mean). Required when <code>outer_fold=True</code>.</p> <code>True</code> <code>outer_fold</code> <code>bool</code> <p>Aggregate outer folds after inner aggregation.</p> <code>True</code> <code>include_std</code> <code>bool</code> <p>Also return a std DataFrame.</p> <code>False</code> <p>Returns:</p> Type Description <p>tuple[pd.DataFrame, pd.DataFrame | None]: <code>(mean, std)</code> where std</p> <p>is <code>None</code> unless <code>include_std=True</code>. When <code>inner_fold=False</code></p> <p>returns the raw DataFrame directly.</p>"},{"location":"reference/collectors/#mllabs.collector.StackingCollector","title":"<code>mllabs.collector.StackingCollector</code>","text":"<p>               Bases: <code>Collector</code></p> <p>Collects out-of-fold (OOF) predictions for stacking.</p> <p>Predictions are aggregated across inner folds and saved per outer fold, then assembled into a dataset aligned to the original data index.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Collector name.</p> required <code>connector</code> <code>Connector</code> <p>Node matching criteria. The <code>edges</code> <code>'y'</code> entry is used to extract the target column.</p> required <code>output_var</code> <p>Column selector for the Head output.</p> required <code>experimenter</code> <code>Experimenter</code> <p>Used to build the OOF index and target.</p> required <code>method</code> <code>str</code> <p>Inner-fold aggregation \u2014 <code>'mean'</code> (default), <code>'mode'</code>, or <code>'simple'</code> (concatenate).</p> <code>'mean'</code>"},{"location":"reference/collectors/#mllabs.collector.StackingCollector.get_dataset","title":"<code>get_dataset(nodes=None, include_target=True)</code>","text":"<p>Return OOF predictions as a DataFrame aligned to the original index.</p> <p>Parameters:</p> Name Type Description Default <code>nodes</code> <p>Node query. <code>None</code> returns all collected nodes.</p> <code>None</code> <code>include_target</code> <code>bool</code> <p>Append the target column(s) if available.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>DataFrame</code> <p>OOF prediction columns (+ target) indexed to match</p> <p>the original dataset.</p>"},{"location":"reference/collectors/#mllabs.collector.ModelAttrCollector","title":"<code>mllabs.collector.ModelAttrCollector</code>","text":"<p>               Bases: <code>Collector</code></p> <p>Collects model attributes (e.g. feature importances) for each fold.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Collector name.</p> required <code>connector</code> <code>Connector</code> <p>Node matching criteria. Used to infer the adapter from <code>connector.processor</code> when adapter is <code>None</code>.</p> required <code>result_key</code> <code>str</code> <p>Key in the adapter's <code>result_objs</code> dict (e.g. <code>'feature_importances'</code>).</p> required <code>adapter</code> <code>ModelAdapter</code> <p>Explicit adapter. Auto-inferred from <code>connector.processor</code> if omitted.</p> <code>None</code> <code>params</code> <code>dict</code> <p>Extra keyword arguments forwarded to the result extractor function.</p> <code>None</code>"},{"location":"reference/collectors/#mllabs.collector.ModelAttrCollector.get_attr","title":"<code>get_attr(node, idx=None)</code>","text":""},{"location":"reference/collectors/#mllabs.collector.ModelAttrCollector.get_attrs","title":"<code>get_attrs(nodes=None)</code>","text":""},{"location":"reference/collectors/#mllabs.collector.ModelAttrCollector.get_attrs_agg","title":"<code>get_attrs_agg(node, agg_inner=True, agg_outer=True)</code>","text":"<p>Return aggregated model attributes across folds.</p> <p>Only valid for mergeable result types (<code>result_objs[key][1] == True</code>).</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>str</code> <p>Node name.</p> required <code>agg_inner</code> <code>bool</code> <p>Average inner folds. Required when <code>agg_outer=True</code>.</p> <code>True</code> <code>agg_outer</code> <code>bool</code> <p>Average outer folds after inner aggregation. Returns a <code>pd.Series</code> when both are <code>True</code>.</p> <code>True</code> <p>Returns:</p> Type Description <p>pd.Series | pd.DataFrame: Aggregated result.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the result type is not mergeable or <code>agg_outer=True</code> while <code>agg_inner=False</code>.</p>"},{"location":"reference/collectors/#mllabs.collector.SHAPCollector","title":"<code>mllabs.collector.SHAPCollector</code>","text":"<p>               Bases: <code>Collector</code></p> <p>Computes SHAP values and feature importance for each fold.</p> <p>Applies an optional <code>data_filter</code> to subsample rows before computing SHAP values. Supports tree-based multiclass models (3-D SHAP arrays are averaged over the class axis).</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Collector name.</p> required <code>connector</code> <code>Connector</code> <p>Node matching criteria.</p> required <code>explainer_cls</code> <p>SHAP explainer class. Default <code>shap.TreeExplainer</code>.</p> <code>None</code> <code>data_filter</code> <code>DataFilter</code> <p>Applied to train and valid data before calling the explainer.</p> <code>None</code>"},{"location":"reference/collectors/#mllabs.collector.SHAPCollector.get_feature_importance","title":"<code>get_feature_importance(node, idx)</code>","text":"<p>Return per-inner-fold feature importance for one outer fold.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>str</code> <p>Node name.</p> required <code>idx</code> <code>int</code> <p>Outer fold index.</p> required <p>Returns:</p> Type Description <p>list[pd.Series]: One Series per inner fold (mean absolute SHAP</p> <p>values over samples).</p>"},{"location":"reference/collectors/#mllabs.collector.SHAPCollector.get_feature_importance_agg","title":"<code>get_feature_importance_agg(node, agg_inner='mean', agg_outer='mean')</code>","text":"<p>Return aggregated feature importance across all folds.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>str</code> <p>Node name.</p> required <code>agg_inner</code> <code>str | None</code> <p>Aggregation function name for inner folds (passed to <code>pd.DataFrame.agg</code>). <code>None</code> keeps inner fold axis as a MultiIndex level.</p> <code>'mean'</code> <code>agg_outer</code> <code>str | None</code> <p>Aggregation function name for outer folds. <code>None</code> returns a DataFrame with one column per outer fold.</p> <code>'mean'</code> <p>Returns:</p> Type Description <p>pd.Series | pd.DataFrame: When both agg_inner and agg_outer are</p> <p>set, returns a <code>pd.Series</code>. When agg_outer is <code>None</code>, returns</p> <p>a DataFrame. When agg_inner is <code>None</code>, returns a MultiIndex DataFrame.</p>"},{"location":"reference/collectors/#mllabs.collector.OutputCollector","title":"<code>mllabs.collector.OutputCollector</code>","text":"<p>               Bases: <code>Collector</code></p> <p>Saves raw train/valid outputs to disk for each fold.</p> <p>Data is stored as <code>{path}/{node}/{idx}_{inner_idx}.pkl</code>.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Collector name.</p> required <code>connector</code> <code>Connector</code> <p>Node matching criteria.</p> required <code>output_var</code> <p>Column selector applied to Head output.</p> required <code>include_target</code> <code>bool</code> <p>Whether to save target alongside output.</p> <code>True</code>"},{"location":"reference/collectors/#mllabs.collector.OutputCollector.get_output","title":"<code>get_output(node, idx, inner_idx)</code>","text":"<p>Load saved output for a specific fold.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>str</code> <p>Node name.</p> required <code>idx</code> <code>int</code> <p>Outer fold index.</p> required <code>inner_idx</code> <code>int</code> <p>Inner fold index.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <p>``{'output_train': (train_arr, valid_sub_arr),</p> <p>'output_valid': arr, 'columns': [...]}``.</p>"},{"location":"reference/collectors/#mllabs.collector.OutputCollector.get_outputs","title":"<code>get_outputs(node)</code>","text":"<p>Load all saved outputs for a node.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>str</code> <p>Node name.</p> required <p>Returns:</p> Type Description <p>dict[tuple[int, int], dict]: <code>{(idx, inner_idx): entry}</code> for all</p> <p>saved folds.</p>"},{"location":"reference/connector/","title":"Connector","text":""},{"location":"reference/connector/#mllabs.Connector","title":"<code>mllabs.Connector</code>","text":"<p>Selects nodes by matching against name, processor, and/or edges.</p> <p>All provided criteria are combined with AND logic. Omitted criteria always match.</p> <p>Parameters:</p> Name Type Description Default <code>node_query</code> <p>Node name filter. A <code>str</code> is treated as a regex pattern; a <code>list</code> requires exact membership.</p> <code>None</code> <code>edges</code> <p>Edge filter. <code>{key: [(node_name, var_spec), ...]}</code> \u2014 the node's edges must contain all listed entries (contain-based matching).</p> <code>None</code> <code>processor</code> <p>Processor class filter. The node's resolved processor must be exactly this class.</p> <code>None</code>"},{"location":"reference/connector/#mllabs.Connector.match","title":"<code>match(node_name, node_attrs)</code>","text":"<p>Return True if the node satisfies all configured criteria.</p> <p>Parameters:</p> Name Type Description Default <code>node_name</code> <code>str</code> <p>Node name to test.</p> required <code>node_attrs</code> <code>dict</code> <p>Resolved node attributes from <code>Pipeline.get_node_attrs()</code>.</p> required <p>Returns:</p> Name Type Description <code>bool</code> <p>True if all criteria match.</p>"},{"location":"reference/experimenter/","title":"Experimenter","text":""},{"location":"reference/experimenter/#mllabs._experimenter.Experimenter","title":"<code>mllabs._experimenter.Experimenter</code>","text":"<p>Executes and manages a Pipeline experiment on a single dataset.</p> <p>Splits data using sp (outer) and optionally sp_v (inner), then runs Stage builds and Head experiments fold-by-fold.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <p>Input dataset (pandas DataFrame, polars DataFrame, or numpy array).</p> required <code>path</code> <code>str | Path</code> <p>Directory for persisting experiment artifacts.</p> required <code>data_names</code> <code>list[str]</code> <p>Column names override.</p> <code>None</code> <code>sp</code> <p>Outer splitter (sklearn splitter API). Default <code>ShuffleSplit(n_splits=1, random_state=1)</code>.</p> <code>ShuffleSplit(n_splits=1, random_state=1)</code> <code>sp_v</code> <p>Inner splitter for nested cross-validation. <code>None</code> disables.</p> <code>None</code> <code>splitter_params</code> <code>dict</code> <p>Maps splitter keyword args to column names in data, e.g. <code>{'y': 'target'}</code>.</p> <code>None</code> <code>title</code> <code>str</code> <p>Human-readable experiment title.</p> <code>None</code> <code>data_key</code> <code>str</code> <p>Identifier verified on :meth:<code>load</code> to prevent data mismatch.</p> <code>None</code> <code>cache_maxsize</code> <code>int</code> <p>Stage output cache size in bytes. Default 4 GB.</p> <code>4 * 1024 ** 3</code> <code>logger</code> <p>Logger instance. Default <code>DefaultLogger(level=['info', 'progress'])</code>.</p> <code>DefaultLogger(level=['info', 'progress'])</code> <p>Attributes:</p> Name Type Description <code>pipeline</code> <code>Pipeline</code> <p>The pipeline being experimented on.</p> <code>node_objs</code> <code>dict</code> <p><code>{node_name: StageObj | HeadObj}</code>.</p> <code>cache</code> <code>DataCache</code> <p>Shared LRU cache.</p> <code>collectors</code> <code>dict</code> <p>Registered :class:<code>~mllabs.collector.Collector</code> instances.</p> <code>trainers</code> <code>dict</code> <p>Registered :class:<code>~mllabs._trainer.Trainer</code> instances.</p> <code>status</code> <code>str</code> <p><code>'open'</code> or <code>'closed'</code>.</p>"},{"location":"reference/experimenter/#mllabs._experimenter.Experimenter.create","title":"<code>create(data, path, data_names=None, sp=ShuffleSplit(n_splits=1, random_state=1), sp_v=None, splitter_params=None, title=None, data_key=None, cache_maxsize=4 * 1024 ** 3, logger=DefaultLogger(level=['info', 'progress']))</code>  <code>staticmethod</code>","text":""},{"location":"reference/experimenter/#mllabs._experimenter.Experimenter.load","title":"<code>load(filepath, data, data_key=None)</code>  <code>staticmethod</code>","text":"<p>Load a saved Experimenter from disk.</p> <p>Parameters:</p> Name Type Description Default <code>filepath</code> <code>str | Path</code> <p>Path to the experiment directory (contains <code>__exp.pkl</code>).</p> required <code>data</code> <p>Dataset to attach. Must match the original data shape.</p> required <code>data_key</code> <code>str</code> <p>If the saved experiment has a <code>data_key</code>, this must match.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Experimenter</code> <p>Restored experimenter with all nodes, collectors, and</p> <p>trainers reloaded.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>data_key</code> does not match the saved value.</p>"},{"location":"reference/experimenter/#mllabs._experimenter.Experimenter.set_grp","title":"<code>set_grp(name, role=None, processor=None, edges=None, method=None, parent=None, adapter=None, params=None, exist='diff')</code>","text":""},{"location":"reference/experimenter/#mllabs._experimenter.Experimenter.set_node","title":"<code>set_node(name, grp, processor=None, edges=None, method=None, adapter=None, params=None, exist='diff')</code>","text":""},{"location":"reference/experimenter/#mllabs._experimenter.Experimenter.rename_grp","title":"<code>rename_grp(name_from, name_to)</code>","text":""},{"location":"reference/experimenter/#mllabs._experimenter.Experimenter.remove_grp","title":"<code>remove_grp(name)</code>","text":""},{"location":"reference/experimenter/#mllabs._experimenter.Experimenter.remove_node","title":"<code>remove_node(name)</code>","text":"<p>\ub178\ub4dc\ub97c \uc81c\uac70</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <p>\uc81c\uac70\ud560 \ub178\ub4dc \uc774\ub984</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>\ub178\ub4dc\uac00 \uc874\uc7ac\ud558\uc9c0 \uc54a\uac70\ub098, \uc790\uc2dd \ub178\ub4dc\uac00 \uc788\ub294 \uacbd\uc6b0</p>"},{"location":"reference/experimenter/#mllabs._experimenter.Experimenter.build","title":"<code>build(nodes=None, rebuild=False)</code>","text":"<p>Build Stage nodes.</p> <p>Parameters:</p> Name Type Description Default <code>nodes</code> <p>Node query \u2014 <code>None</code> (all stages), <code>list</code>, or regex <code>str</code>.</p> <code>None</code> <code>rebuild</code> <code>bool</code> <p>If <code>True</code>, rebuild already-built nodes.</p> <code>False</code>"},{"location":"reference/experimenter/#mllabs._experimenter.Experimenter.exp","title":"<code>exp(nodes=None)</code>","text":"<p>Run Head nodes and invoke all matching Collectors.</p> <p>Parameters:</p> Name Type Description Default <code>nodes</code> <p>Node query \u2014 <code>None</code> (all heads), <code>list</code>, or regex <code>str</code>.</p> <code>None</code>"},{"location":"reference/experimenter/#mllabs._experimenter.Experimenter.reset_nodes","title":"<code>reset_nodes(nodes)</code>","text":"<p>Reset nodes to <code>init</code> state.</p> <p>Removes node objects, clears cache entries, and resets Collector and Trainer data for the affected nodes.</p> <p>Parameters:</p> Name Type Description Default <code>nodes</code> <code>list[str]</code> <p>Node names to reset.</p> required"},{"location":"reference/experimenter/#mllabs._experimenter.Experimenter.show_error_nodes","title":"<code>show_error_nodes(nodes=None, traceback=False)</code>","text":"<p>Print nodes in <code>error</code> state.</p> <p>Parameters:</p> Name Type Description Default <code>nodes</code> <p>Node query to filter. <code>None</code> checks all nodes.</p> <code>None</code> <code>traceback</code> <code>bool</code> <p>Include full traceback in output.</p> <code>False</code>"},{"location":"reference/experimenter/#mllabs._experimenter.Experimenter.finalize","title":"<code>finalize(nodes)</code>","text":"<p>Release memory for built Head nodes (<code>built</code> \u2192 <code>finalized</code>).</p> <p>Disk artifacts are preserved so nodes can be reloaded.</p> <p>Parameters:</p> Name Type Description Default <code>nodes</code> <p>Node query for Head nodes to finalize.</p> required"},{"location":"reference/experimenter/#mllabs._experimenter.Experimenter.reinitialize","title":"<code>reinitialize(nodes)</code>","text":""},{"location":"reference/experimenter/#mllabs._experimenter.Experimenter.close_exp","title":"<code>close_exp()</code>","text":"<p>Finalize all built nodes and mark the experiment as closed.</p> <p>Collector data is preserved. After this call, :attr:<code>status</code> is <code>'closed'</code> and no further builds or experiments are permitted until :meth:<code>reopen_exp</code> is called.</p>"},{"location":"reference/experimenter/#mllabs._experimenter.Experimenter.reopen_exp","title":"<code>reopen_exp()</code>","text":"<p>Reopen a closed experiment and rebuild Stage nodes.</p> <p>Clears all node objects, sets status back to <code>'open'</code>, then calls :meth:<code>build</code>.</p>"},{"location":"reference/experimenter/#mllabs._experimenter.Experimenter.add_collector","title":"<code>add_collector(collector, exist='skip')</code>","text":"<p>Register a Collector and immediately collect from built Head nodes.</p> <p>Parameters:</p> Name Type Description Default <code>collector</code> <code>Collector</code> <p>Collector instance to register.</p> required <code>exist</code> <code>str</code> <p><code>'skip'</code> (default) returns existing if already registered; <code>'error'</code> raises.</p> <code>'skip'</code> <p>Returns:</p> Name Type Description <code>Collector</code> <p>The registered collector.</p>"},{"location":"reference/experimenter/#mllabs._experimenter.Experimenter.get_collector","title":"<code>get_collector(name)</code>","text":""},{"location":"reference/experimenter/#mllabs._experimenter.Experimenter.remove_collector","title":"<code>remove_collector(name)</code>","text":""},{"location":"reference/experimenter/#mllabs._experimenter.Experimenter.collect","title":"<code>collect(collector, exist='skip')</code>","text":"<p>Run a Collector ad-hoc over already-built Head nodes.</p> <p>Parameters:</p> Name Type Description Default <code>collector</code> <code>Collector</code> <p>Collector instance to run.</p> required <code>exist</code> <code>str</code> <p><code>'skip'</code> (default) skips nodes already collected.</p> <code>'skip'</code> <p>Returns:</p> Name Type Description <code>Collector</code> <p>The same collector after collection.</p>"},{"location":"reference/experimenter/#mllabs._experimenter.Experimenter.add_trainer","title":"<code>add_trainer(name, data=None, splitter='same', splitter_params=None, exist='skip')</code>","text":"<p>Create and register a Trainer.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Trainer name.</p> required <code>data</code> <p>Dataset for the Trainer. <code>None</code> \u2192 use Experimenter's data.</p> <code>None</code> <code>splitter</code> <p>Splitter to use. <code>'same'</code> reuses <code>sp_v</code>; pass a sklearn splitter object for a custom split strategy; <code>None</code> trains on the full dataset.</p> <code>'same'</code> <code>splitter_params</code> <code>dict</code> <p>Column mappings for the splitter. Must be <code>None</code> when <code>splitter='same'</code>.</p> <code>None</code> <code>exist</code> <code>str</code> <p><code>'skip'</code> (default) returns existing if name already registered; <code>'error'</code> raises.</p> <code>'skip'</code> <p>Returns:</p> Name Type Description <code>Trainer</code> <p>The newly created (or existing) Trainer.</p>"},{"location":"reference/experimenter/#mllabs._experimenter.Experimenter.get_trainer","title":"<code>get_trainer(name)</code>","text":""},{"location":"reference/experimenter/#mllabs._experimenter.Experimenter.remove_trainer","title":"<code>remove_trainer(name)</code>","text":""},{"location":"reference/experimenter/#mllabs._experimenter.Experimenter.get_node_output","title":"<code>get_node_output(node, idx, v=None)</code>","text":""},{"location":"reference/experimenter/#mllabs._experimenter.Experimenter.get_node_train_output","title":"<code>get_node_train_output(node, idx, v=None)</code>","text":""},{"location":"reference/experimenter/#mllabs._experimenter.Experimenter.get_node_valid_output","title":"<code>get_node_valid_output(node, idx, v=None)</code>","text":""},{"location":"reference/experimenter/#mllabs._experimenter.Experimenter.get_n_splits","title":"<code>get_n_splits()</code>","text":""},{"location":"reference/experimenter/#mllabs._experimenter.Experimenter.get_n_splits_inner","title":"<code>get_n_splits_inner()</code>","text":""},{"location":"reference/experimenter/#mllabs._experimenter.Experimenter.desc_status","title":"<code>desc_status()</code>","text":""},{"location":"reference/experimenter/#mllabs._experimenter.Experimenter.desc_spec","title":"<code>desc_spec()</code>","text":""},{"location":"reference/experimenter/#mllabs._experimenter.Experimenter.desc_pipeline","title":"<code>desc_pipeline(max_depth=None, direction='TD')</code>","text":""},{"location":"reference/experimenter/#mllabs._experimenter.Experimenter.desc_node","title":"<code>desc_node(node_name, direction='TD', show_params=False)</code>","text":""},{"location":"reference/experimenter/#mllabs._experimenter.DataCache","title":"<code>mllabs._experimenter.DataCache</code>","text":"<p>LRU cache for Stage node outputs, keyed by <code>(node, type, fold_idx)</code>.</p> <p>Capacity is measured in bytes using <code>nbytes</code> / <code>memory_usage</code>.</p> <p>Parameters:</p> Name Type Description Default <code>maxsize</code> <code>int</code> <p>Maximum cache capacity in bytes. Default 4 GB.</p> <code>4 * 1024 ** 3</code>"},{"location":"reference/experimenter/#mllabs._experimenter.DataCache.get_data","title":"<code>get_data(node, typ, idx)</code>","text":""},{"location":"reference/experimenter/#mllabs._experimenter.DataCache.put_data","title":"<code>put_data(node, typ, idx, data)</code>","text":""},{"location":"reference/experimenter/#mllabs._experimenter.DataCache.clear_nodes","title":"<code>clear_nodes(nodes)</code>","text":""},{"location":"reference/filters/","title":"Filters","text":""},{"location":"reference/filters/#mllabs.DataFilter","title":"<code>mllabs.DataFilter</code>","text":"<p>Base class for data filters used with :class:<code>~mllabs.collector.SHAPCollector</code>.</p> <p>Subclasses implement :meth:<code>_select</code> to return a row index array. The filter is applied to all arrays in the input <code>data_dict</code> identically.</p>"},{"location":"reference/filters/#mllabs.DataFilter.__call__","title":"<code>__call__(data_dict)</code>","text":"<p>Apply the filter to every array in data_dict.</p> <p>Parameters:</p> Name Type Description Default <code>data_dict</code> <code>dict</code> <p><code>{key: DataWrapper}</code> mapping.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <p>Filtered <code>{key: DataWrapper}</code> with rows selected by</p> <p>meth:<code>_select</code>.</p>"},{"location":"reference/filters/#mllabs.RandomFilter","title":"<code>mllabs.RandomFilter</code>","text":"<p>               Bases: <code>DataFilter</code></p> <p>Randomly subsample rows from a data dict.</p> <p>Parameters:</p> Name Type Description Default <code>n</code> <code>int</code> <p>Absolute number of rows to sample. Mutually exclusive with frac.</p> <code>None</code> <code>frac</code> <code>float</code> <p>Fraction of rows to sample (0\u20131). Mutually exclusive with n.</p> <code>None</code> <code>random_state</code> <code>int</code> <p>Random seed for reproducibility.</p> <code>None</code>"},{"location":"reference/filters/#mllabs.IndexFilter","title":"<code>mllabs.IndexFilter</code>","text":"<p>               Bases: <code>DataFilter</code></p> <p>Select rows whose index values appear in a provided index array.</p> <p>Parameters:</p> Name Type Description Default <code>index</code> <code>array - like</code> <p>The set of index values to keep.</p> required"},{"location":"reference/inferencer/","title":"Inferencer","text":""},{"location":"reference/inferencer/#mllabs._inferencer.Inferencer","title":"<code>mllabs._inferencer.Inferencer</code>","text":"<p>Applies trained processors to new data for inference.</p> <p>Created by :meth:<code>~mllabs._trainer.Trainer.to_inferencer</code>. Self-contained \u2014 no dependency on Experimenter or Trainer at serve time.</p> <p>Attributes:</p> Name Type Description <code>pipeline</code> <code>Pipeline</code> <p>Minimal pipeline (selected nodes only).</p> <code>selected_stages</code> <code>list[str]</code> <p>Stage node names.</p> <code>selected_heads</code> <code>list[str]</code> <p>Head node names.</p> <code>n_splits</code> <code>int</code> <p>Number of cross-validation splits.</p> <code>node_objs</code> <code>dict</code> <p><code>{node_name: [processor_split0, ...]}</code>.</p> <code>v</code> <p>Output column filter applied to Head outputs.</p>"},{"location":"reference/inferencer/#mllabs._inferencer.Inferencer.process","title":"<code>process(data, agg='mean')</code>","text":"<p>Run inference on new data and aggregate across splits.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <p>Input dataset (pandas/polars DataFrame or numpy array).</p> required <code>agg</code> <code>str | callable | None</code> <p>Aggregation strategy across splits. <code>'mean'</code> (default), <code>'mode'</code>, a callable receiving a list of per-split DataFrames, or <code>None</code> (returns list). Ignored when <code>n_splits == 1</code>.</p> <code>'mean'</code> <p>Returns:</p> Type Description <p>DataFrame | list: Aggregated predictions, or a list of per-split</p> <p>predictions when <code>agg=None</code>.</p>"},{"location":"reference/inferencer/#mllabs._inferencer.Inferencer.save","title":"<code>save(path)</code>","text":"<p>Serialize the Inferencer to a single file.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>Directory to save into. Creates <code>{path}/__inferencer.pkl</code>.</p> required"},{"location":"reference/inferencer/#mllabs._inferencer.Inferencer.load","title":"<code>load(path)</code>  <code>classmethod</code>","text":"<p>Load a saved Inferencer from disk.</p> <p>Parameters:</p> Name Type Description Default <code>path</code> <code>str | Path</code> <p>Directory containing <code>__inferencer.pkl</code>.</p> required <p>Returns:</p> Name Type Description <code>Inferencer</code> <p>Restored inferencer.</p>"},{"location":"reference/pipeline/","title":"Pipeline","text":""},{"location":"reference/pipeline/#mllabs._pipeline.Pipeline","title":"<code>mllabs._pipeline.Pipeline</code>","text":"<p>Node graph that describes an ML workflow.</p> <p>Holds groups (:class:<code>PipelineGroup</code>) and nodes (:class:<code>PipelineNode</code>). The implicit DataSource node is stored as <code>nodes[None]</code>.</p> <p>Attributes:</p> Name Type Description <code>grps</code> <code>dict[str, PipelineGroup]</code> <p>All registered groups.</p> <code>nodes</code> <code>dict[str | None, PipelineNode]</code> <p>All nodes, keyed by name. <code>None</code> is the DataSource.</p>"},{"location":"reference/pipeline/#mllabs._pipeline.Pipeline.set_grp","title":"<code>set_grp(name, role=None, processor=None, edges=None, method=None, parent=None, adapter=None, params=None, exist='diff')</code>","text":"<p>Create or update a group.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Group name. Cannot contain <code>__</code> or path-invalid chars.</p> required <code>role</code> <code>str</code> <p><code>'stage'</code> or <code>'head'</code>. Inherited from parent if omitted.</p> <code>None</code> <code>processor</code> <p>Processor class.</p> <code>None</code> <code>edges</code> <code>dict</code> <p>Edge definitions <code>{key: [(node_name, var_spec), ...]}</code>.</p> <code>None</code> <code>method</code> <code>str</code> <p>Processor method name (e.g. <code>'fit_transform'</code>).</p> <code>None</code> <code>parent</code> <code>str</code> <p>Parent group name, or <code>None</code>.</p> <code>None</code> <code>adapter</code> <p>ModelAdapter instance.</p> <code>None</code> <code>params</code> <code>dict</code> <p>Constructor parameters for the processor.</p> <code>None</code> <code>exist</code> <code>str</code> <p>Conflict resolution \u2014 <code>'diff'</code> (default, skip if unchanged), <code>'skip'</code>, <code>'error'</code>, or <code>'replace'</code>.</p> <code>'diff'</code> <p>Returns:</p> Name Type Description <code>dict</code> <p><code>{result, grp, affected_nodes, [old_grp]}</code> where result is</p> <p><code>'new'</code>, <code>'skip'</code>, or <code>'update'</code>.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If name is invalid, role conflicts, or edges form a cycle.</p>"},{"location":"reference/pipeline/#mllabs._pipeline.Pipeline.set_node","title":"<code>set_node(name, grp, processor=None, edges=None, method=None, adapter=None, params=None, exist='diff')</code>","text":"<p>Create or update a node.</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Node name.</p> required <code>grp</code> <code>str</code> <p>Group the node belongs to.</p> required <code>processor</code> <p>Processor class override.</p> <code>None</code> <code>edges</code> <code>dict</code> <p>Additional edge definitions merged on top of the group.</p> <code>None</code> <code>method</code> <code>str</code> <p>Method name override.</p> <code>None</code> <code>adapter</code> <p>ModelAdapter instance override.</p> <code>None</code> <code>params</code> <code>dict</code> <p>Constructor parameter overrides.</p> <code>None</code> <code>exist</code> <code>str</code> <p>Conflict resolution \u2014 <code>'diff'</code> (default), <code>'skip'</code>, <code>'error'</code>, or <code>'replace'</code>.</p> <code>'diff'</code> <p>Returns:</p> Name Type Description <code>dict</code> <p><code>{result, obj, old_obj, affected_nodes}</code>.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If the resolved processor or method is missing, edges are invalid, or a cycle would be created.</p>"},{"location":"reference/pipeline/#mllabs._pipeline.Pipeline.get_node_names","title":"<code>get_node_names(query)</code>","text":"<p>Resolve a node query to a list of node names.</p> <p>Parameters:</p> Name Type Description Default <code>query</code> <p><code>None</code> (all nodes), <code>list</code> (exact names), or <code>str</code> (regex pattern matched against node names).</p> required <p>Returns:</p> Type Description <p>list[str]: Matching node names (DataSource <code>None</code> excluded for</p> <p>str/list queries).</p>"},{"location":"reference/pipeline/#mllabs._pipeline.Pipeline.get_node_attrs","title":"<code>get_node_attrs(name)</code>","text":"<p>Return fully resolved attributes for a node (group hierarchy merged).</p> <p>Parameters:</p> Name Type Description Default <code>name</code> <code>str</code> <p>Node name.</p> required <p>Returns:</p> Name Type Description <code>dict</code> <p>Keys \u2014 <code>name</code>, <code>grp</code>, <code>processor</code>, <code>method</code>,</p> <p><code>adapter</code>, <code>edges</code>, <code>params</code>.</p>"},{"location":"reference/pipeline/#mllabs._pipeline.Pipeline.get_node","title":"<code>get_node(name)</code>","text":""},{"location":"reference/pipeline/#mllabs._pipeline.Pipeline.get_grp","title":"<code>get_grp(name)</code>","text":""},{"location":"reference/pipeline/#mllabs._pipeline.Pipeline.rename_grp","title":"<code>rename_grp(name_from, name_to)</code>","text":""},{"location":"reference/pipeline/#mllabs._pipeline.Pipeline.remove_grp","title":"<code>remove_grp(name)</code>","text":""},{"location":"reference/pipeline/#mllabs._pipeline.Pipeline.remove_node","title":"<code>remove_node(name)</code>","text":""},{"location":"reference/pipeline/#mllabs._pipeline.Pipeline.copy","title":"<code>copy()</code>","text":"<p>Return a deep copy of the entire pipeline.</p> <p>Returns:</p> Name Type Description <code>Pipeline</code> <p>New pipeline with all groups and nodes copied.</p>"},{"location":"reference/pipeline/#mllabs._pipeline.Pipeline.copy_stage","title":"<code>copy_stage()</code>","text":"<p>Return a copy containing only Stage groups and nodes.</p> <p>Returns:</p> Name Type Description <code>Pipeline</code> <p>Pipeline with only <code>role='stage'</code> groups and nodes.</p>"},{"location":"reference/pipeline/#mllabs._pipeline.Pipeline.copy_nodes","title":"<code>copy_nodes(node_names)</code>","text":"<p>Return a copy containing the specified nodes and all their ancestors.</p> <p>Parameters:</p> Name Type Description Default <code>node_names</code> <code>list[str]</code> <p>Target node names. Their upstream Stage dependencies are included automatically.</p> required <p>Returns:</p> Name Type Description <code>Pipeline</code> <p>Minimal pipeline needed to run node_names.</p>"},{"location":"reference/pipeline/#mllabs._pipeline.Pipeline.compare_nodes","title":"<code>compare_nodes(nodes)</code>","text":"<p>Compare params and X-edges across nodes that share the same processor.</p> <p>Nodes are grouped by processor class. Within each group, only columns that differ between nodes are included.</p> <p>Parameters:</p> Name Type Description Default <code>nodes</code> <code>list[str]</code> <p>Node names to compare.</p> required <p>Returns:</p> Type Description <p>dict[str, pd.DataFrame]: <code>{processor_name: DataFrame}</code> where the</p> <p>DataFrame index is node names and columns are a MultiIndex of</p> <p><code>('params', param_key)</code> and <code>('X', stage_label)</code>.</p>"},{"location":"reference/pipeline/#mllabs._pipeline.Pipeline.desc_pipeline","title":"<code>desc_pipeline(max_depth=None, direction='TD')</code>","text":"<p>\ud30c\uc774\ud504\ub77c\uc778 \uad6c\uc870\ub97c Mermaid Markdown\uc73c\ub85c \ubc18\ud658</p> <p>Parameters:</p> Name Type Description Default <code>max_depth</code> <p>\ucd5c\ub300 \ud45c\uc2dc \uae4a\uc774 (None\uc774\uba74 \ubb34\uc81c\ud55c)</p> <code>None</code> <code>direction</code> <p>\uadf8\ub798\ud504 \ubc29\ud5a5 ('TD': Top-Down, 'LR': Left-Right)</p> <code>'TD'</code>"},{"location":"reference/pipeline/#mllabs._pipeline.Pipeline.desc_node","title":"<code>desc_node(node_name, direction='TD', show_params=False)</code>","text":"<p>\ud2b9\uc815 \ub178\ub4dc\uae4c\uc9c0\uc758 \uc5f0\uacb0 \uad6c\uc870\ub97c Mermaid Markdown\uc73c\ub85c \ubc18\ud658</p> <p>Parameters:</p> Name Type Description Default <code>node_name</code> <p>\ub300\uc0c1 \ub178\ub4dc \uc774\ub984</p> required <code>direction</code> <p>\uadf8\ub798\ud504 \ubc29\ud5a5 ('TD': Top-Down, 'LR': Left-Right)</p> <code>'TD'</code> <code>show_params</code> <p>True\uc774\uba74 \ub178\ub4dc\uc758 \ud30c\ub77c\ubbf8\ud130 \uc815\ubcf4\ub97c \ud45c\uc2dc (default: False)</p> <code>False</code>"},{"location":"reference/pipeline/#mllabs._pipeline.PipelineGroup","title":"<code>mllabs._pipeline.PipelineGroup</code>","text":"<p>A named group that shares configuration across its member nodes.</p> <p>Groups form a hierarchy via <code>parent</code>. Child groups and their nodes inherit <code>processor</code>, <code>method</code>, <code>adapter</code>, <code>edges</code>, and <code>params</code> from ancestors, with child values taking precedence.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Group name.</p> <code>role</code> <code>str</code> <p><code>'stage'</code> or <code>'head'</code>.</p> <code>processor</code> <p>Processor class (optional, may be inherited).</p> <code>edges</code> <code>dict</code> <p>Edge definitions (optional, merged with parent).</p> <code>method</code> <code>str</code> <p>Processor method name (optional, may be inherited).</p> <code>parent</code> <code>str</code> <p>Parent group name, or <code>None</code>.</p> <code>adapter</code> <p>ModelAdapter instance (optional, may be inherited).</p> <code>params</code> <code>dict</code> <p>Constructor parameters (optional, merged with parent).</p> <code>children</code> <code>list[str]</code> <p>Child group names.</p> <code>nodes</code> <code>list[str]</code> <p>Node names belonging to this group.</p>"},{"location":"reference/pipeline/#mllabs._pipeline.PipelineGroup.get_attrs","title":"<code>get_attrs(grps)</code>","text":""},{"location":"reference/pipeline/#mllabs._pipeline.PipelineGroup.diff","title":"<code>diff(processor=None, edges=None, method=None, parent=None, adapter=None, params=None)</code>","text":""},{"location":"reference/pipeline/#mllabs._pipeline.PipelineNode","title":"<code>mllabs._pipeline.PipelineNode</code>","text":"<p>An individual executable unit in the pipeline.</p> <p>Node-level attributes override group attributes. Final resolved values are obtained via :meth:<code>get_attrs</code>.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Node name.</p> <code>grp</code> <code>str</code> <p>Parent group name.</p> <code>processor</code> <p>Processor class override (<code>None</code> \u2192 inherit from group).</p> <code>edges</code> <code>dict</code> <p>Additional or overriding edge definitions.</p> <code>method</code> <code>str</code> <p>Processor method name override.</p> <code>adapter</code> <p>ModelAdapter instance override.</p> <code>params</code> <code>dict</code> <p>Constructor parameter overrides.</p> <code>output_edges</code> <code>list[str]</code> <p>Names of nodes that consume this node's output.</p>"},{"location":"reference/pipeline/#mllabs._pipeline.PipelineNode.get_attrs","title":"<code>get_attrs(grps)</code>","text":""},{"location":"reference/pipeline/#mllabs._pipeline.PipelineNode.diff","title":"<code>diff(grp, processor=None, edges=None, method=None, adapter=None, params=None)</code>","text":""},{"location":"reference/trainer/","title":"Trainer","text":""},{"location":"reference/trainer/#mllabs._trainer.Trainer","title":"<code>mllabs._trainer.Trainer</code>","text":"<p>Runs cross-validation training on a subset of Pipeline nodes.</p> <p>Created via :meth:<code>~mllabs.Experimenter.add_trainer</code>. Shares the Experimenter's Pipeline and DataCache.</p> <p>Attributes:</p> Name Type Description <code>name</code> <code>str</code> <p>Trainer name.</p> <code>selected_stages</code> <code>list[str]</code> <p>Stage nodes included in training.</p> <code>selected_heads</code> <code>list[str]</code> <p>Head nodes to train.</p> <code>split_indices</code> <code>list[tuple] | None</code> <p><code>[(train_idx, valid_idx), ...]</code> or <code>None</code> if no splitting.</p> <code>node_objs</code> <code>dict</code> <p><code>{node_name: TrainStageObj | TrainHeadObj}</code>.</p>"},{"location":"reference/trainer/#mllabs._trainer.Trainer.select_head","title":"<code>select_head(nodes)</code>","text":"<p>Specify Head nodes to train and auto-collect their upstream Stages.</p> <p>Parameters:</p> Name Type Description Default <code>nodes</code> <p>Node query \u2014 <code>list</code>, regex <code>str</code>, or <code>None</code> (all heads).</p> required"},{"location":"reference/trainer/#mllabs._trainer.Trainer.train","title":"<code>train()</code>","text":"<p>Train all unbuilt selected nodes across all splits.</p> <p>Nodes are trained in topological order. Each node completes all splits before the next node begins.</p>"},{"location":"reference/trainer/#mllabs._trainer.Trainer.process","title":"<code>process(data, v=None)</code>","text":"<p>Apply trained processors to new data, yielding one result per split.</p> <p>Parameters:</p> Name Type Description Default <code>data</code> <p>Input dataset.</p> required <code>v</code> <p>Output column filter applied to Head outputs.</p> <code>None</code> <p>Yields:</p> Name Type Description <code>DataFrame</code> <p>Concatenated Head outputs for each split.</p>"},{"location":"reference/trainer/#mllabs._trainer.Trainer.to_inferencer","title":"<code>to_inferencer(v=None)</code>","text":"<p>Export trained processors to a standalone :class:<code>~mllabs.Inferencer</code>.</p> <p>All selected nodes must be in <code>built</code> state.</p> <p>Parameters:</p> Name Type Description Default <code>v</code> <p>Output column filter passed to the Inferencer.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>Inferencer</code> <p>Independent inferencer ready for deployment.</p> <p>Raises:</p> Type Description <code>RuntimeError</code> <p>If any selected node is not built.</p>"},{"location":"reference/trainer/#mllabs._trainer.Trainer.reset_nodes","title":"<code>reset_nodes(nodes)</code>","text":""},{"location":"reference/trainer/#mllabs._trainer.Trainer.get_n_splits","title":"<code>get_n_splits()</code>","text":""},{"location":"serving/inferencer/","title":"Serving Guide (Inferencer)","text":"<p><code>Inferencer</code> packages the fitted processors from a cross-validation <code>Trainer</code> into a single, self-contained object for deployment. It has no dependency on <code>Experimenter</code> or <code>Trainer</code> at serve time.</p>"},{"location":"serving/inferencer/#exporting-from-trainer","title":"Exporting from Trainer","text":"<p>After <code>train()</code> completes, call <code>to_inferencer()</code> to extract the fitted processors:</p> <pre><code>trainer.select_head(['lgbm_v1'])\ntrainer.train()\n\ninferencer = trainer.to_inferencer(\n    v=None,   # optionally filter output columns (same as Trainer.process v)\n)\n</code></pre> <p><code>to_inferencer()</code> copies the processors out of the Trainer. The resulting <code>Inferencer</code> is independent \u2014 you can discard the Trainer afterwards.</p>"},{"location":"serving/inferencer/#saving-and-loading","title":"Saving and Loading","text":"<p>The entire <code>Inferencer</code> \u2014 pipeline structure, all split processors, and configuration \u2014 is serialized into a single file.</p> <p>Save:</p> <pre><code>inferencer.save('./model/inferencer')\n# Writes: ./model/inferencer/__inferencer.pkl\n</code></pre> <p>Load:</p> <pre><code>from mllabs import Inferencer\n\ninferencer = Inferencer.load('./model/inferencer')\n</code></pre> <p>No training dependencies (Experimenter, Trainer, Collectors) are required to load or run an Inferencer.</p>"},{"location":"serving/inferencer/#running-inference","title":"Running Inference","text":"<pre><code>predictions = inferencer.process(test_df, agg='mean')\n</code></pre> <p><code>process()</code> applies each split's processors to the input data in sequence (Stage transforms \u2192 Head prediction), then aggregates across splits.</p> <p>Input can be any pandas/polars/numpy object that the pipeline was trained on.</p>"},{"location":"serving/inferencer/#aggregation-strategies","title":"Aggregation Strategies","text":"<code>agg</code> Behaviour Use when <code>'mean'</code> (default) Element-wise mean across splits Regression, probability outputs <code>'mode'</code> Element-wise mode across splits Classification with hard labels <code>callable</code> <code>agg(results)</code> where <code>results</code> is a list of per-split DataFrames Custom ensembling logic <code>None</code> Returns a list of per-split results Debugging, manual aggregation <p>When <code>n_splits == 1</code>, aggregation is skipped and the single split result is returned directly regardless of <code>agg</code>.</p> <p>Custom aggregation example:</p> <pre><code>import numpy as np\n\ndef weighted_mean(results):\n    # weight later splits more heavily\n    weights = np.linspace(1, 2, len(results))\n    stacked = np.stack([r.values for r in results], axis=0)\n    return (stacked * weights[:, None, None]).sum(axis=0) / weights.sum()\n\npredictions = inferencer.process(test_df, agg=weighted_mean)\n</code></pre>"},{"location":"serving/inferencer/#dependency-requirements","title":"Dependency Requirements","text":"<p>At serve time, only the following are needed:</p> <ul> <li><code>ml-labs</code> (core package)</li> <li>The framework libraries used by the trained processors (e.g., <code>lightgbm</code>, <code>xgboost</code>)</li> <li>Not needed: <code>scikit-learn</code> splitters, Collectors, Trainer, or any training-only dependencies</li> </ul> <p>This means a serving environment can install a minimal subset:</p> <pre><code>pip install ml-labs lightgbm\n</code></pre>"}]}